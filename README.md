# DDSP-Timbre-Transfer (48kHz)

This repository contains a **Differentiable Digital Signal Processing (DDSP)** model trained for **timbre transformation** at **48kHz**.  
The model enables users to input an audio signal (e.g., guitar, vocal, synth, etc.) and transform its timbre towards a target sound, while preserving the expressive dynamics and temporal structure of the original performance.

>  General-purpose: although this checkpoint was trained on a specific target dataset, the approach is **not tied to one instrument** (e.g., saxophone). By retraining on your own dataset, you can morph any input source into the desired timbre.

---

##  Features
- **Sample Rate:** 48 kHz (high-quality, studio-ready).  
- **End-to-End Timbre Transfer:** Input audio â†’ Extract features (f0, loudness) â†’ Resynthesized output.  
- **DDSP-based synthesis:** Combines harmonic oscillator with learned parameters, ensuring natural and expressive results.  
- **TorchScript Export:** Model is TorchScript-compiled for portability in Python, C++, and JUCE plugins.  
- **Generalizable Pipeline:** Replace dataset to adapt to other instruments/timbres.  

---

## ğŸ“‚ Repository Structure
```bash
DDSP-Timbre-Transfer/
â”‚
â”œâ”€â”€ ckpt/ # Pretrained TorchScript/DDSP models
â”‚ â””â”€â”€ timbre_48k.ts # TorchScript model (48kHz timbre transfer)
â”‚
â”œâ”€â”€ configs/ # Training & model config files
â”‚ â””â”€â”€ timbre_48k.yaml # Example configuration
â”‚
â”œâ”€â”€ data_48k/ # Put your data inside this folder
â”‚ â””â”€â”€ sax # Example data
â”‚
â”œâ”€â”€ ddsp_model/                   # Core DDSP implementation
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ autoencoder.py        # AutoEncoder architecture
â”‚   â”‚   â”œâ”€â”€ autoencoder_wrapper.py# Wrapper for training & inference
â”‚   â”‚   â”œâ”€â”€ decoder.py            # Decoder module
â”‚   â”‚   â”œâ”€â”€ encoder.py            # Encoder module
â”‚   â”‚   â””â”€â”€ torchscript_wrapper.py# TorchScript-ready wrapper
â”‚   â”‚
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ filtered_noise.py     # Filtered noise generator
â”‚   â”‚   â”œâ”€â”€ harmonic_oscillator.py# Harmonic oscillator module
â”‚   â”‚   â”œâ”€â”€ loudness_extractor.py # Loudness feature extractor
â”‚   â”‚   â”œâ”€â”€ pitch_extractor.py    # Pitch (f0) extractor
â”‚   â”‚   â”œâ”€â”€ reverb.py             # Reverb module
â”‚   â”‚   â””â”€â”€ ptcrepe/   
â”‚   â”‚
â”‚   â””â”€â”€ training/                    # Utility functions
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ scripts/                      # Inference and conversion scripts
â”‚   â”œâ”€â”€ test_torchscript.py       # Test inference with TorchScript model
â”‚   â”œâ”€â”€ export_torchscript.py     # Export PyTorch -> TorchScript
â”‚   â”œâ”€â”€ extract_f0_crepe.py
â”‚   â”œâ”€â”€	test.py
â”‚   â””â”€â”€ train.py                  # training entry point
â”‚
â”œâ”€â”€ README.md # Documentation (this file)
â””â”€â”€ requirements.txt # Dependencies
```
---

---

## âš™ï¸ Installation

1. **Clone the repository:**
```bash
git clone https://github.com/your-username/DDSP-Timbre-Transfer.git
cd DDSP-Timbre-Transfer
```
2. Set up environment (Python 3.9+ recommended):
```bash
conda create -n ddsp python=3.9
conda activate ddsp
pip install -r requirements.txt
```
---

## Main dependencies:

- torch >= 2.0

- torchaudio

- librosa

- numpy

- soundfile

---
## ğŸ§ Usage
1. Test inference with TorchScript model

Run inference on your audio file:
```bash
python scripts/test_torchscript.py \
    --input examples/input.wav \
    --output examples/output.wav \
    --ts_model ckpt/timbre_48k.ts \
    --config configs/timbre_48k.yaml \
    --wave_length 768000
```
---
## ğŸ¹ Training Your Own Model

You can adapt the pipeline for your dataset:

1.Prepare dataset:

-train/ and test/ audio folders

-Mono .wav files at 48kHz

2.Modify config:
```bash
train:

  dataset_path: ./data/your_dataset
  sample_rate: 48000
  batch_size: 16
  ...
```

3.Train:
```bash
python train.py --config configs/your_config.yaml
```

4.Export to TorchScript:
```bash
python scripts/export_torchscript.py --ckpt path/to/checkpoint.pth --output ckpt/your_model.ts
```
---
## ğŸ“¢ Notes
-The provided model is pretrained for demonstration and timbre transfer at 48kHz.

-Results may vary depending on the source audio. For best quality, retrain with your target instrument or timbre dataset.

-Compatible with Python and C++ (LibTorch / JUCE) environments.

---
## ğŸ“œ License

This project is released under the MIT License.
Feel free to use and modify for research or personal projects.

 Developed by Danial Kooshki
ğŸ“§danial.kooshki@gmail.com
ğŸ“§ info@danialkooshki.com

ğŸŒ [www.danialkooshki.com](https://www.danialkooshki.com)
